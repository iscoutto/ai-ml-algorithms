{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede neural artificial - Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e teste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Normalização da features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento da RNA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 0.6689 - val_loss: 0.6428\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6330 - val_loss: 0.6100\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5969 - val_loss: 0.5740\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5604 - val_loss: 0.5373\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5218 - val_loss: 0.4946\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4810 - val_loss: 0.4507\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4343 - val_loss: 0.4097\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3933 - val_loss: 0.3636\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3519 - val_loss: 0.3239\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3155 - val_loss: 0.2893\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.2641\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2613 - val_loss: 0.2403\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2411 - val_loss: 0.2209\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2266 - val_loss: 0.2127\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2138 - val_loss: 0.1956\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1973 - val_loss: 0.1857\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1859 - val_loss: 0.1822\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1763 - val_loss: 0.1709\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1693 - val_loss: 0.1635\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1599 - val_loss: 0.1608\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1525 - val_loss: 0.1525\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1466 - val_loss: 0.1509\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1394 - val_loss: 0.1461\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1345 - val_loss: 0.1408\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1283 - val_loss: 0.1388\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1219 - val_loss: 0.1348\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1199 - val_loss: 0.1357\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1156 - val_loss: 0.1322\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1163 - val_loss: 0.1293\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1079 - val_loss: 0.1257\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1094 - val_loss: 0.1255\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1099 - val_loss: 0.1272\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1166 - val_loss: 0.1241\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1015 - val_loss: 0.1226\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0920 - val_loss: 0.1270\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0926 - val_loss: 0.1182\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0868 - val_loss: 0.1247\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0857 - val_loss: 0.1171\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0832 - val_loss: 0.1178\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0818 - val_loss: 0.1156\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0794 - val_loss: 0.1199\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0795 - val_loss: 0.1176\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.1117\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0782 - val_loss: 0.1246\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.1122\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0758 - val_loss: 0.1246\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0768 - val_loss: 0.1129\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0708 - val_loss: 0.1167\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.1146\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0699 - val_loss: 0.1149\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0682 - val_loss: 0.1136\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0674 - val_loss: 0.1125\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0681 - val_loss: 0.1087\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0664 - val_loss: 0.1148\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0661 - val_loss: 0.1127\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0646 - val_loss: 0.1149\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.1133\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0642 - val_loss: 0.1142\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0632 - val_loss: 0.1155\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0617 - val_loss: 0.1131\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0628 - val_loss: 0.1213\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0615 - val_loss: 0.1070\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0651 - val_loss: 0.1257\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0637 - val_loss: 0.1090\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0625 - val_loss: 0.1151\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0588 - val_loss: 0.1159\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0590 - val_loss: 0.1119\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0575 - val_loss: 0.1205\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.1114\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0604 - val_loss: 0.1132\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0585 - val_loss: 0.1114\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0581 - val_loss: 0.1112\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0567 - val_loss: 0.1145\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0554 - val_loss: 0.1134\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0557 - val_loss: 0.1117\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0559 - val_loss: 0.1180\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0560 - val_loss: 0.1095\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0616 - val_loss: 0.1212\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0555 - val_loss: 0.1130\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0541 - val_loss: 0.1137\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.1258\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0561 - val_loss: 0.1206\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0588 - val_loss: 0.1103\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0549 - val_loss: 0.1247\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0530 - val_loss: 0.1187\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0528 - val_loss: 0.1129\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0532 - val_loss: 0.1231\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0541 - val_loss: 0.1206\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0531 - val_loss: 0.1201\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0520 - val_loss: 0.1170\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0524 - val_loss: 0.1135\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0521 - val_loss: 0.1158\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.1151\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0511 - val_loss: 0.1190\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0523 - val_loss: 0.1148\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0515 - val_loss: 0.1177\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0500 - val_loss: 0.1173\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0502 - val_loss: 0.1163\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.1274\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0493 - val_loss: 0.1176\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.1139\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0550 - val_loss: 0.1242\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0542 - val_loss: 0.1138\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0511 - val_loss: 0.1319\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.1143\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0508 - val_loss: 0.1205\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0471 - val_loss: 0.1138\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.1245\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.1150\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0500 - val_loss: 0.1250\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0504 - val_loss: 0.1250\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0484 - val_loss: 0.1243\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0530 - val_loss: 0.1118\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0496 - val_loss: 0.1206\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.1228\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0460 - val_loss: 0.1202\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.1235\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.1237\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.1215\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0488 - val_loss: 0.1157\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0471 - val_loss: 0.1199\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.1193\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.1233\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.1194\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.1289\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.1272\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0497 - val_loss: 0.1198\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.1319\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.1250\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.1267\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0440 - val_loss: 0.1277\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.1185\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0428 - val_loss: 0.1241\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.1276\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0438 - val_loss: 0.1241\n",
      "Epoch 136/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.1251\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.1246\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0431 - val_loss: 0.1194\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0435 - val_loss: 0.1259\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0415 - val_loss: 0.1236\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0420 - val_loss: 0.1269\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0420 - val_loss: 0.1229\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.1248\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0411 - val_loss: 0.1306\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0431 - val_loss: 0.1270\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0411 - val_loss: 0.1248\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0406 - val_loss: 0.1309\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0405 - val_loss: 0.1242\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0405 - val_loss: 0.1327\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0419 - val_loss: 0.1266\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0412 - val_loss: 0.1258\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0414 - val_loss: 0.1266\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.1280\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0463 - val_loss: 0.1325\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.1308\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0405 - val_loss: 0.1257\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.1325\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0406 - val_loss: 0.1260\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0393 - val_loss: 0.1276\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0393 - val_loss: 0.1278\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0387 - val_loss: 0.1308\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.1312\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.1296\n",
      "Epoch 164/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.1271\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.1233\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.1474\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.1223\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.1244\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.1283\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0461 - val_loss: 0.1416\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0430 - val_loss: 0.1198\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0405 - val_loss: 0.1326\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0388 - val_loss: 0.1322\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.1291\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.1224\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0379 - val_loss: 0.1316\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0394 - val_loss: 0.1287\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.1207\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0377 - val_loss: 0.1338\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0423 - val_loss: 0.1243\n",
      "Epoch 181/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.1293\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0384 - val_loss: 0.1276\n",
      "Epoch 183/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.1262\n",
      "Epoch 184/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.1238\n",
      "Epoch 185/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0377 - val_loss: 0.1310\n",
      "Epoch 186/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.1293\n",
      "Epoch 187/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.1282\n",
      "Epoch 188/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.1282\n",
      "Epoch 189/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.1379\n",
      "Epoch 190/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0397 - val_loss: 0.1233\n",
      "Epoch 191/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.1378\n",
      "Epoch 192/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.1368\n",
      "Epoch 193/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.1530\n",
      "Epoch 194/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.1289\n",
      "Epoch 195/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.1287\n",
      "Epoch 196/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.1289\n",
      "Epoch 197/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.1259\n",
      "Epoch 198/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.1353\n",
      "Epoch 199/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.1221\n",
      "Epoch 200/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0355 - val_loss: 0.1403\n",
      "Epoch 201/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.1179\n",
      "Epoch 202/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.1461\n",
      "Epoch 203/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.1326\n",
      "Epoch 204/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1340\n",
      "Epoch 205/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.1241\n",
      "Epoch 206/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.1311\n",
      "Epoch 207/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.1324\n",
      "Epoch 208/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.1294\n",
      "Epoch 209/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.1206\n",
      "Epoch 210/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.1450\n",
      "Epoch 211/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.1292\n",
      "Epoch 212/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0355 - val_loss: 0.1208\n",
      "Epoch 213/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.1394\n",
      "Epoch 214/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1211\n",
      "Epoch 215/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1447\n",
      "Epoch 216/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0350 - val_loss: 0.1217\n",
      "Epoch 217/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.1392\n",
      "Epoch 218/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.1367\n",
      "Epoch 219/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.1347\n",
      "Epoch 220/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.1311\n",
      "Epoch 221/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.1311\n",
      "Epoch 222/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.1341\n",
      "Epoch 223/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.1452\n",
      "Epoch 224/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0339 - val_loss: 0.1282\n",
      "Epoch 225/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1404\n",
      "Epoch 226/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.1274\n",
      "Epoch 227/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.1392\n",
      "Epoch 228/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.1263\n",
      "Epoch 229/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1500\n",
      "Epoch 230/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.1289\n",
      "Epoch 231/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1298\n",
      "Epoch 232/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.1333\n",
      "Epoch 233/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.1339\n",
      "Epoch 234/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.1233\n",
      "Epoch 235/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.1313\n",
      "Epoch 236/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.1223\n",
      "Epoch 237/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.1358\n",
      "Epoch 238/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.1388\n",
      "Epoch 239/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.1226\n",
      "Epoch 240/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.1411\n",
      "Epoch 241/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.1330\n",
      "Epoch 242/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1409\n",
      "Epoch 243/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.1265\n",
      "Epoch 244/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1287\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1297\n",
      "Epoch 246/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.1353\n",
      "Epoch 247/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.1389\n",
      "Epoch 248/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1244\n",
      "Epoch 249/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.1438\n",
      "Epoch 250/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.1264\n",
      "Epoch 251/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.1286\n",
      "Epoch 252/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.1357\n",
      "Epoch 253/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.1333\n",
      "Epoch 254/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1319\n",
      "Epoch 255/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.1322\n",
      "Epoch 256/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.1271\n",
      "Epoch 257/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0350 - val_loss: 0.1537\n",
      "Epoch 258/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1359\n",
      "Epoch 259/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0304 - val_loss: 0.1376\n",
      "Epoch 260/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.1299\n",
      "Epoch 261/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.1306\n",
      "Epoch 262/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.1293\n",
      "Epoch 263/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.1327\n",
      "Epoch 264/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.1295\n",
      "Epoch 265/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0316 - val_loss: 0.1372\n",
      "Epoch 266/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.1270\n",
      "Epoch 267/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.1404\n",
      "Epoch 268/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.1352\n",
      "Epoch 269/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.1319\n",
      "Epoch 270/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0423 - val_loss: 0.1266\n",
      "Epoch 271/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.1335\n",
      "Epoch 272/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.1378\n",
      "Epoch 273/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.1310\n",
      "Epoch 274/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.1289\n",
      "Epoch 275/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.1259\n",
      "Epoch 276/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.1336\n",
      "Epoch 277/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.1364\n",
      "Epoch 278/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.1290\n",
      "Epoch 279/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.1316\n",
      "Epoch 280/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.1381\n",
      "Epoch 281/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.1264\n",
      "Epoch 282/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1346\n",
      "Epoch 283/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.1276\n",
      "Epoch 284/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.1294\n",
      "Epoch 285/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.1319\n",
      "Epoch 286/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.1332\n",
      "Epoch 287/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.1313\n",
      "Epoch 288/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.1308\n",
      "Epoch 289/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.1360\n",
      "Epoch 290/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.1241\n",
      "Epoch 291/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.1284\n",
      "Epoch 292/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.1257\n",
      "Epoch 293/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.1443\n",
      "Epoch 294/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.1336\n",
      "Epoch 295/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.1370\n",
      "Epoch 296/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.1344\n",
      "Epoch 297/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.1413\n",
      "Epoch 298/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.1299\n",
      "Epoch 299/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.1379\n",
      "Epoch 300/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.1412\n",
      "Epoch 301/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.1224\n",
      "Epoch 302/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.1312\n",
      "Epoch 303/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.1267\n",
      "Epoch 304/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.1417\n",
      "Epoch 305/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.1452\n",
      "Epoch 306/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.1300\n",
      "Epoch 307/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.1427\n",
      "Epoch 308/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.1443\n",
      "Epoch 309/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.1294\n",
      "Epoch 310/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.1605\n",
      "Epoch 311/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.1271\n",
      "Epoch 312/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.1435\n",
      "Epoch 313/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.1319\n",
      "Epoch 314/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.1448\n",
      "Epoch 315/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.1434\n",
      "Epoch 316/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.1361\n",
      "Epoch 317/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0228 - val_loss: 0.1359\n",
      "Epoch 318/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.1388\n",
      "Epoch 319/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.1421\n",
      "Epoch 320/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.1342\n",
      "Epoch 321/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.1469\n",
      "Epoch 322/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.1358\n",
      "Epoch 323/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.1421\n",
      "Epoch 324/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.1437\n",
      "Epoch 325/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.1262\n",
      "Epoch 326/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.1309\n",
      "Epoch 327/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.1346\n",
      "Epoch 328/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.1301\n",
      "Epoch 329/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.1409\n",
      "Epoch 330/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.1323\n",
      "Epoch 331/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.1394\n",
      "Epoch 332/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.1263\n",
      "Epoch 333/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.1359\n",
      "Epoch 334/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.1351\n",
      "Epoch 335/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.1406\n",
      "Epoch 336/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.1394\n",
      "Epoch 337/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.1314\n",
      "Epoch 338/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.1358\n",
      "Epoch 339/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.1346\n",
      "Epoch 340/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.1357\n",
      "Epoch 341/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.1328\n",
      "Epoch 342/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0256 - val_loss: 0.1430\n",
      "Epoch 343/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.1353\n",
      "Epoch 344/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.1299\n",
      "Epoch 345/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.1386\n",
      "Epoch 346/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.1287\n",
      "Epoch 347/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.1416\n",
      "Epoch 348/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.1448\n",
      "Epoch 349/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.1342\n",
      "Epoch 350/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.1368\n",
      "Epoch 351/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.1358\n",
      "Epoch 352/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.1462\n",
      "Epoch 353/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.1457\n",
      "Epoch 354/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.1378\n",
      "Epoch 355/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.1474\n",
      "Epoch 356/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.1421\n",
      "Epoch 357/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.1408\n",
      "Epoch 358/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.1454\n",
      "Epoch 359/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.1359\n",
      "Epoch 360/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.1411\n",
      "Epoch 361/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.1349\n",
      "Epoch 362/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.1402\n",
      "Epoch 363/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.1461\n",
      "Epoch 364/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.1446\n",
      "Epoch 365/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.1364\n",
      "Epoch 366/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.1378\n",
      "Epoch 367/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.1519\n",
      "Epoch 368/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.1458\n",
      "Epoch 369/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.1328\n",
      "Epoch 370/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.1550\n",
      "Epoch 371/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.1310\n",
      "Epoch 372/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.1464\n",
      "Epoch 373/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.1481\n",
      "Epoch 374/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.1453\n",
      "Epoch 375/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.1438\n",
      "Epoch 376/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.1443\n",
      "Epoch 377/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.1595\n",
      "Epoch 378/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.1344\n",
      "Epoch 379/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.1490\n",
      "Epoch 380/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.1415\n",
      "Epoch 381/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.1413\n",
      "Epoch 382/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.1503\n",
      "Epoch 383/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.1565\n",
      "Epoch 384/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.1363\n",
      "Epoch 385/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.1565\n",
      "Epoch 386/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.1489\n",
      "Epoch 387/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.1404\n",
      "Epoch 388/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.1513\n",
      "Epoch 389/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.1388\n",
      "Epoch 390/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.1585\n",
      "Epoch 391/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.1465\n",
      "Epoch 392/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.1457\n",
      "Epoch 393/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.1505\n",
      "Epoch 394/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.1483\n",
      "Epoch 395/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.1566\n",
      "Epoch 396/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1613\n",
      "Epoch 397/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.1645\n",
      "Epoch 398/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.1550\n",
      "Epoch 399/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.1556\n",
      "Epoch 400/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.1540\n",
      "Epoch 401/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.1497\n",
      "Epoch 402/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1532\n",
      "Epoch 403/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.1531\n",
      "Epoch 404/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.1500\n",
      "Epoch 405/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.1566\n",
      "Epoch 406/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.1552\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.1558\n",
      "Epoch 408/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.1473\n",
      "Epoch 409/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.1566\n",
      "Epoch 410/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.1604\n",
      "Epoch 411/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.1573\n",
      "Epoch 412/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.1529\n",
      "Epoch 413/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.1547\n",
      "Epoch 414/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.1629\n",
      "Epoch 415/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.1611\n",
      "Epoch 416/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.1608\n",
      "Epoch 417/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.1685\n",
      "Epoch 418/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.1625\n",
      "Epoch 419/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.1621\n",
      "Epoch 420/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.1752\n",
      "Epoch 421/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.1717\n",
      "Epoch 422/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.1581\n",
      "Epoch 423/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.1638\n",
      "Epoch 424/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0349 - val_loss: 0.2071\n",
      "Epoch 425/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0292 - val_loss: 0.1607\n",
      "Epoch 426/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.1697\n",
      "Epoch 427/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.1637\n",
      "Epoch 428/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.1768\n",
      "Epoch 429/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.1625\n",
      "Epoch 430/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.1644\n",
      "Epoch 431/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.1651\n",
      "Epoch 432/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.1649\n",
      "Epoch 433/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.1678\n",
      "Epoch 434/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.1671\n",
      "Epoch 435/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.1653\n",
      "Epoch 436/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.1688\n",
      "Epoch 437/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.1734\n",
      "Epoch 438/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.1700\n",
      "Epoch 439/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.1684\n",
      "Epoch 440/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.1704\n",
      "Epoch 441/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.1829\n",
      "Epoch 442/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.1718\n",
      "Epoch 443/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.1852\n",
      "Epoch 444/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.1715\n",
      "Epoch 445/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.1751\n",
      "Epoch 446/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.1719\n",
      "Epoch 447/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.1782\n",
      "Epoch 448/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.1739\n",
      "Epoch 449/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.1765\n",
      "Epoch 450/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.1827\n",
      "Epoch 451/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.1834\n",
      "Epoch 452/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.1832\n",
      "Epoch 453/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.1779\n",
      "Epoch 454/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.1989\n",
      "Epoch 455/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.1768\n",
      "Epoch 456/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.1858\n",
      "Epoch 457/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.1827\n",
      "Epoch 458/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.1942\n",
      "Epoch 459/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.1832\n",
      "Epoch 460/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.1893\n",
      "Epoch 461/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.1901\n",
      "Epoch 462/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.1945\n",
      "Epoch 463/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.1909\n",
      "Epoch 464/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.1863\n",
      "Epoch 465/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.1907\n",
      "Epoch 466/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.1929\n",
      "Epoch 467/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.1885\n",
      "Epoch 468/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.1929\n",
      "Epoch 469/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.1938\n",
      "Epoch 470/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.1930\n",
      "Epoch 471/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.1932\n",
      "Epoch 472/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.1944\n",
      "Epoch 473/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.2083\n",
      "Epoch 474/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.1935\n",
      "Epoch 475/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.1954\n",
      "Epoch 476/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2000\n",
      "Epoch 477/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.2054\n",
      "Epoch 478/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.2062\n",
      "Epoch 479/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.2073\n",
      "Epoch 480/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.2020\n",
      "Epoch 481/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.2027\n",
      "Epoch 482/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.2031\n",
      "Epoch 483/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.2000\n",
      "Epoch 484/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.2065\n",
      "Epoch 485/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.2013\n",
      "Epoch 486/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.2033\n",
      "Epoch 487/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.2028\n",
      "Epoch 488/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.2104\n",
      "Epoch 489/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2036\n",
      "Epoch 490/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.2110\n",
      "Epoch 491/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.2134\n",
      "Epoch 492/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.2333\n",
      "Epoch 493/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2165\n",
      "Epoch 494/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.2121\n",
      "Epoch 495/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2147\n",
      "Epoch 496/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.2206\n",
      "Epoch 497/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2112\n",
      "Epoch 498/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2104\n",
      "Epoch 499/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.2307\n",
      "Epoch 500/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.2243\n",
      "Epoch 501/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2193\n",
      "Epoch 502/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2124\n",
      "Epoch 503/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2171\n",
      "Epoch 504/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2332\n",
      "Epoch 505/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2217\n",
      "Epoch 506/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2440\n",
      "Epoch 507/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.2257\n",
      "Epoch 508/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.2369\n",
      "Epoch 509/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.2181\n",
      "Epoch 510/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2273\n",
      "Epoch 511/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.2248\n",
      "Epoch 512/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.2286\n",
      "Epoch 513/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.2299\n",
      "Epoch 514/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.2284\n",
      "Epoch 515/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.2396\n",
      "Epoch 516/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2251\n",
      "Epoch 517/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.2333\n",
      "Epoch 518/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2249\n",
      "Epoch 519/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.2306\n",
      "Epoch 520/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.2434\n",
      "Epoch 521/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.2426\n",
      "Epoch 522/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.2296\n",
      "Epoch 523/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.2398\n",
      "Epoch 524/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.2453\n",
      "Epoch 525/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2344\n",
      "Epoch 526/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.2580\n",
      "Epoch 527/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.2285\n",
      "Epoch 528/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.2533\n",
      "Epoch 529/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2296\n",
      "Epoch 530/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.2522\n",
      "Epoch 531/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2309\n",
      "Epoch 532/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2479\n",
      "Epoch 533/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2313\n",
      "Epoch 534/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.2477\n",
      "Epoch 535/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.2436\n",
      "Epoch 536/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2388\n",
      "Epoch 537/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.2577\n",
      "Epoch 538/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.2338\n",
      "Epoch 539/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.2628\n",
      "Epoch 540/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.2350\n",
      "Epoch 541/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.2426\n",
      "Epoch 542/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.2648\n",
      "Epoch 543/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.2411\n",
      "Epoch 544/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.2533\n",
      "Epoch 545/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.2442\n",
      "Epoch 546/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.2598\n",
      "Epoch 547/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.2505\n",
      "Epoch 548/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.2518\n",
      "Epoch 549/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.2453\n",
      "Epoch 550/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.2723\n",
      "Epoch 551/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.2527\n",
      "Epoch 552/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.2618\n",
      "Epoch 553/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.2576\n",
      "Epoch 554/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.2557\n",
      "Epoch 555/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.2533\n",
      "Epoch 556/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.2583\n",
      "Epoch 557/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.2598\n",
      "Epoch 558/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.2623\n",
      "Epoch 559/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.2681\n",
      "Epoch 560/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.2652\n",
      "Epoch 561/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.2672\n",
      "Epoch 562/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.2688\n",
      "Epoch 563/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.2885\n",
      "Epoch 564/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.2636\n",
      "Epoch 565/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.2715\n",
      "Epoch 566/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.2611\n",
      "Epoch 567/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.2761\n",
      "Epoch 568/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.2791\n",
      "Epoch 569/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.2625\n",
      "Epoch 570/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.2863\n",
      "Epoch 571/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2675\n",
      "Epoch 572/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.2830\n",
      "Epoch 573/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.2705\n",
      "Epoch 574/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.2905\n",
      "Epoch 575/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.2694\n",
      "Epoch 576/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.2804\n",
      "Epoch 577/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.2712\n",
      "Epoch 578/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.2847\n",
      "Epoch 579/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.2784\n",
      "Epoch 580/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.2804\n",
      "Epoch 581/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2884\n",
      "Epoch 582/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.2714\n",
      "Epoch 583/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.2970\n",
      "Epoch 584/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.2789\n",
      "Epoch 585/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.2874\n",
      "Epoch 586/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.2763\n",
      "Epoch 587/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.2771\n",
      "Epoch 588/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.2879\n",
      "Epoch 589/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.2819\n",
      "Epoch 590/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.2851\n",
      "Epoch 591/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.2804\n",
      "Epoch 592/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.3234\n",
      "Epoch 593/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.2719\n",
      "Epoch 594/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.2989\n",
      "Epoch 595/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.2915\n",
      "Epoch 596/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.3417\n",
      "Epoch 597/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2880\n",
      "Epoch 598/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.3000\n",
      "Epoch 599/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.3077\n",
      "Epoch 600/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.2902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc4662795b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, \n",
    "          y = y_train, \n",
    "          epochs = 600,\n",
    "          validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evitando o Overfitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop training when a monitored quantity has stopped improving.\n",
    "\n",
    "    Arguments:\n",
    "        monitor: Quantity to be monitored.\n",
    "        min_delta: Minimum change in the monitored quantity\n",
    "            to qualify as an improvement, i.e. an absolute\n",
    "            change of less than min_delta, will count as no\n",
    "            improvement.\n",
    "        patience: Number of epochs with no improvement\n",
    "            after which training will be stopped.\n",
    "        verbose: verbosity mode.\n",
    "        mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
    "            training will stop when the quantity\n",
    "            monitored has stopped decreasing; in `max`\n",
    "            mode it will stop when the quantity\n",
    "            monitored has stopped increasing; in `auto`\n",
    "            mode, the direction is automatically inferred\n",
    "            from the name of the monitored quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 14ms/step - loss: 0.7030 - val_loss: 0.6754\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.6493\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6158\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.5787\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5611 - val_loss: 0.5317\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5083 - val_loss: 0.4607\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4426 - val_loss: 0.4015\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3896 - val_loss: 0.3520\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3449 - val_loss: 0.3100\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3089 - val_loss: 0.2776\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2845 - val_loss: 0.2599\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2632 - val_loss: 0.2354\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2448 - val_loss: 0.2209\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2306 - val_loss: 0.2035\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2173 - val_loss: 0.1932\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2056 - val_loss: 0.1816\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1914 - val_loss: 0.1731\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1819 - val_loss: 0.1653\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1716 - val_loss: 0.1557\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1616 - val_loss: 0.1507\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1537 - val_loss: 0.1430\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1500 - val_loss: 0.1419\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1431 - val_loss: 0.1332\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1345 - val_loss: 0.1311\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1270 - val_loss: 0.1254\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1231 - val_loss: 0.1282\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1171 - val_loss: 0.1206\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1097 - val_loss: 0.1225\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1076 - val_loss: 0.1175\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1003 - val_loss: 0.1158\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0964 - val_loss: 0.1141\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0939 - val_loss: 0.1098\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0938 - val_loss: 0.1090\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0886 - val_loss: 0.1123\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0839 - val_loss: 0.1073\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0834 - val_loss: 0.1064\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0827 - val_loss: 0.1180\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0871 - val_loss: 0.1049\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0794 - val_loss: 0.1127\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0741 - val_loss: 0.1044\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.1117\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0689 - val_loss: 0.1033\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0709 - val_loss: 0.1068\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0695 - val_loss: 0.1066\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0696 - val_loss: 0.1074\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0692 - val_loss: 0.1024\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0651 - val_loss: 0.1061\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0642 - val_loss: 0.1031\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.1064\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0632 - val_loss: 0.1067\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.1037\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0645 - val_loss: 0.1068\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0627 - val_loss: 0.1039\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0617 - val_loss: 0.1052\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.1043\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.1065\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.1047\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.1022\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.1061\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0656 - val_loss: 0.1098\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0599 - val_loss: 0.1023\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.1103\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.1040\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0536 - val_loss: 0.1087\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.1046\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0536 - val_loss: 0.1098\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0533 - val_loss: 0.1053\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0524 - val_loss: 0.1066\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0527 - val_loss: 0.1053\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0523 - val_loss: 0.1083\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0514 - val_loss: 0.1051\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0519 - val_loss: 0.1069\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.1093\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0516 - val_loss: 0.1078\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.1076\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.1055\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0588 - val_loss: 0.1047\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0535 - val_loss: 0.1150\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.1058\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0496 - val_loss: 0.1147\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.1030\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0468 - val_loss: 0.1132\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.1035\n",
      "Epoch 83: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc466035d00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, \n",
    "          y = y_train, \n",
    "          epochs = 600,\n",
    "          validation_data = (X_test, y_test), verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação do modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        55\n",
      "           1       0.98      0.98      0.98        88\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  2]\n",
      " [ 2 86]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
